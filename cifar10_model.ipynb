{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xtyqg2T1l5rB",
        "outputId": "514b343c-44c5-4b71-a700-f28825cdb739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GPU détecté : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Train: (50000, 32, 32, 3) (50000, 10)\n",
            "Test:  (10000, 32, 32, 3) (10000, 10)\n",
            "Epochs: 50  Batch size: 64\n",
            "➡️ Construction du modèle...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"VGG11_L4R9AI_V6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"VGG11_L4R9AI_V6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m96\u001b[0m)       │        \u001b[38;5;34m55,392\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m96\u001b[0m)       │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m110,720\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">55,392</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">110,720</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m390,346\u001b[0m (1.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">390,346</span> (1.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m389,258\u001b[0m (1.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">389,258</span> (1.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,088\u001b[0m (4.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> (4.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "782/782 - 30s - 39ms/step - accuracy: 0.3783 - loss: 1.7083 - val_accuracy: 0.5252 - val_loss: 1.3459 - learning_rate: 8.0000e-04\n",
            "Epoch 2/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.5444 - loss: 1.2783 - val_accuracy: 0.6457 - val_loss: 0.9978 - learning_rate: 8.0000e-04\n",
            "Epoch 3/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.6297 - loss: 1.0642 - val_accuracy: 0.6804 - val_loss: 0.8983 - learning_rate: 8.0000e-04\n",
            "Epoch 4/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.6781 - loss: 0.9310 - val_accuracy: 0.7435 - val_loss: 0.7385 - learning_rate: 8.0000e-04\n",
            "Epoch 5/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.7134 - loss: 0.8388 - val_accuracy: 0.7215 - val_loss: 0.8163 - learning_rate: 8.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.7383 - loss: 0.7712 - val_accuracy: 0.7747 - val_loss: 0.6601 - learning_rate: 8.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.7585 - loss: 0.7126 - val_accuracy: 0.7897 - val_loss: 0.6070 - learning_rate: 8.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.7719 - loss: 0.6749 - val_accuracy: 0.7954 - val_loss: 0.6073 - learning_rate: 8.0000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.7863 - loss: 0.6346 - val_accuracy: 0.7994 - val_loss: 0.5878 - learning_rate: 8.0000e-04\n",
            "Epoch 10/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.7982 - loss: 0.5939 - val_accuracy: 0.8019 - val_loss: 0.5793 - learning_rate: 8.0000e-04\n",
            "Epoch 11/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8057 - loss: 0.5730 - val_accuracy: 0.8139 - val_loss: 0.5530 - learning_rate: 8.0000e-04\n",
            "Epoch 12/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8169 - loss: 0.5427 - val_accuracy: 0.8130 - val_loss: 0.5610 - learning_rate: 8.0000e-04\n",
            "Epoch 13/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8222 - loss: 0.5272 - val_accuracy: 0.8240 - val_loss: 0.5283 - learning_rate: 8.0000e-04\n",
            "Epoch 14/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8286 - loss: 0.5025 - val_accuracy: 0.8148 - val_loss: 0.5699 - learning_rate: 8.0000e-04\n",
            "Epoch 15/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8337 - loss: 0.4865 - val_accuracy: 0.8100 - val_loss: 0.5724 - learning_rate: 8.0000e-04\n",
            "Epoch 16/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8441 - loss: 0.4634 - val_accuracy: 0.8258 - val_loss: 0.5181 - learning_rate: 8.0000e-04\n",
            "Epoch 17/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8469 - loss: 0.4508 - val_accuracy: 0.8280 - val_loss: 0.5308 - learning_rate: 8.0000e-04\n",
            "Epoch 18/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8513 - loss: 0.4362 - val_accuracy: 0.8372 - val_loss: 0.5009 - learning_rate: 8.0000e-04\n",
            "Epoch 19/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8575 - loss: 0.4200 - val_accuracy: 0.8380 - val_loss: 0.4979 - learning_rate: 8.0000e-04\n",
            "Epoch 20/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8619 - loss: 0.4079 - val_accuracy: 0.8194 - val_loss: 0.5563 - learning_rate: 8.0000e-04\n",
            "Epoch 21/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8656 - loss: 0.3965 - val_accuracy: 0.8387 - val_loss: 0.4981 - learning_rate: 8.0000e-04\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0004799999878741801.\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8673 - loss: 0.3868 - val_accuracy: 0.8282 - val_loss: 0.5414 - learning_rate: 8.0000e-04\n",
            "Epoch 23/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8843 - loss: 0.3392 - val_accuracy: 0.8505 - val_loss: 0.4890 - learning_rate: 4.8000e-04\n",
            "Epoch 24/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8907 - loss: 0.3181 - val_accuracy: 0.8515 - val_loss: 0.4819 - learning_rate: 4.8000e-04\n",
            "Epoch 25/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8909 - loss: 0.3159 - val_accuracy: 0.8493 - val_loss: 0.4989 - learning_rate: 4.8000e-04\n",
            "Epoch 26/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.8955 - loss: 0.3036 - val_accuracy: 0.8537 - val_loss: 0.4961 - learning_rate: 4.8000e-04\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00028799999272450806.\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.8999 - loss: 0.2944 - val_accuracy: 0.8536 - val_loss: 0.4945 - learning_rate: 4.8000e-04\n",
            "Epoch 28/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9063 - loss: 0.2698 - val_accuracy: 0.8550 - val_loss: 0.4924 - learning_rate: 2.8800e-04\n",
            "Epoch 29/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9102 - loss: 0.2583 - val_accuracy: 0.8565 - val_loss: 0.4906 - learning_rate: 2.8800e-04\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001727999886497855.\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9122 - loss: 0.2548 - val_accuracy: 0.8569 - val_loss: 0.5021 - learning_rate: 2.8800e-04\n",
            "Epoch 31/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9204 - loss: 0.2336 - val_accuracy: 0.8606 - val_loss: 0.4880 - learning_rate: 1.7280e-04\n",
            "Epoch 32/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9224 - loss: 0.2264 - val_accuracy: 0.8597 - val_loss: 0.4960 - learning_rate: 1.7280e-04\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00010367999493610114.\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9244 - loss: 0.2215 - val_accuracy: 0.8614 - val_loss: 0.4974 - learning_rate: 1.7280e-04\n",
            "Epoch 34/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9247 - loss: 0.2143 - val_accuracy: 0.8621 - val_loss: 0.4986 - learning_rate: 1.0368e-04\n",
            "Epoch 35/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9272 - loss: 0.2094 - val_accuracy: 0.8641 - val_loss: 0.4964 - learning_rate: 1.0368e-04\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 6.220799696166068e-05.\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9279 - loss: 0.2069 - val_accuracy: 0.8637 - val_loss: 0.4944 - learning_rate: 1.0368e-04\n",
            "Epoch 37/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9301 - loss: 0.2005 - val_accuracy: 0.8642 - val_loss: 0.4954 - learning_rate: 6.2208e-05\n",
            "Epoch 38/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9320 - loss: 0.1955 - val_accuracy: 0.8632 - val_loss: 0.4982 - learning_rate: 6.2208e-05\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.732479817699641e-05.\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9337 - loss: 0.1936 - val_accuracy: 0.8638 - val_loss: 0.5048 - learning_rate: 6.2208e-05\n",
            "Epoch 40/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9324 - loss: 0.1956 - val_accuracy: 0.8634 - val_loss: 0.5019 - learning_rate: 3.7325e-05\n",
            "Epoch 41/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.9352 - loss: 0.1875 - val_accuracy: 0.8645 - val_loss: 0.5040 - learning_rate: 3.7325e-05\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 2.2394878033082933e-05.\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9351 - loss: 0.1906 - val_accuracy: 0.8632 - val_loss: 0.5037 - learning_rate: 3.7325e-05\n",
            "Epoch 43/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9349 - loss: 0.1877 - val_accuracy: 0.8633 - val_loss: 0.5031 - learning_rate: 2.2395e-05\n",
            "Epoch 44/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9326 - loss: 0.1937 - val_accuracy: 0.8632 - val_loss: 0.5046 - learning_rate: 2.2395e-05\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.3436926383292301e-05.\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9348 - loss: 0.1864 - val_accuracy: 0.8633 - val_loss: 0.5053 - learning_rate: 2.2395e-05\n",
            "Epoch 46/50\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.9363 - loss: 0.1849 - val_accuracy: 0.8643 - val_loss: 0.5038 - learning_rate: 1.3437e-05\n",
            "Epoch 47/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9351 - loss: 0.1860 - val_accuracy: 0.8637 - val_loss: 0.5053 - learning_rate: 1.3437e-05\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9372 - loss: 0.1820 - val_accuracy: 0.8650 - val_loss: 0.5057 - learning_rate: 1.3437e-05\n",
            "Epoch 49/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9362 - loss: 0.1826 - val_accuracy: 0.8643 - val_loss: 0.5053 - learning_rate: 1.0000e-05\n",
            "Epoch 50/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.9361 - loss: 0.1797 - val_accuracy: 0.8652 - val_loss: 0.5058 - learning_rate: 1.0000e-05\n",
            "✅ Entraînement terminé en 373.9 s\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.8652 - loss: 0.5058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.5058  Test accuracy: 0.8652\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "VGG11 from scratch pour CIFAR-10 (32x32), simple — sans régularisation, sans callbacks\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Affiche si un GPU est détecté (TF choisit automatiquement)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(\"✅ GPU détecté :\", gpus)\n",
        "else:\n",
        "    print(\"⚠️ Pas de GPU détecté — entraînement sur CPU.\")\n",
        "\n",
        "# Timer minimal\n",
        "class timer:\n",
        "    def __init__(self):\n",
        "        self.start = None\n",
        "        self.stop = None\n",
        "    def tic(self):\n",
        "        self.start = time.time()\n",
        "    def toc(self):\n",
        "        self.stop = time.time()\n",
        "    def res(self):\n",
        "        return None if self.start is None or self.stop is None else self.stop - self.start\n",
        "\n",
        "# VGG11 simple (pas de BatchNorm, pas de dropout)\n",
        "def build_vgg11(input_shape):\n",
        "    model = models.Sequential(name=\"VGG11_L4R9AI_V6\")\n",
        "    model.add(layers.Input(shape=input_shape))\n",
        "\n",
        "    # Bloc 1\n",
        "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2,2)))\n",
        "    model.add(layers.SpatialDropout2D(0.15))\n",
        "\n",
        "    # Bloc 2\n",
        "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2,2)))\n",
        "    model.add(layers.SpatialDropout2D(0.20))\n",
        "\n",
        "    # Nouveau bloc 2.5\n",
        "    model.add(layers.Conv2D(96, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2,2)))\n",
        "    model.add(layers.SpatialDropout2D(0.25))\n",
        "\n",
        "    # Bloc 3\n",
        "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2,2)))\n",
        "    model.add(layers.SpatialDropout2D(0.25))\n",
        "\n",
        "    # Fully connected\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Chargement et préparation des données CIFAR-10\n",
        "class dataset:\n",
        "    def __init__(self, nb_epochs=20, batch_size=64):\n",
        "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "        x_train = x_train.astype('float32') / 255.0\n",
        "        x_test  = x_test.astype('float32') / 255.0\n",
        "\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "        self.input_shape = self.x_train.shape[1:]\n",
        "        self.nb_epochs = nb_epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # one-hot\n",
        "        self.y_train = tf.keras.utils.to_categorical(self.y_train, 10)\n",
        "        self.y_test = tf.keras.utils.to_categorical(self.y_test, 10)\n",
        "\n",
        "        print(\"Train:\", self.x_train.shape, self.y_train.shape)\n",
        "        print(\"Test: \", self.x_test.shape, self.y_test.shape)\n",
        "        print(\"Epochs:\", self.nb_epochs, \" Batch size:\", self.batch_size)\n",
        "\n",
        "# Entraînement simple\n",
        "def train_model(data):\n",
        "    print(\"➡️ Construction du modèle...\")\n",
        "    model = build_vgg11(data.input_shape)\n",
        "\n",
        "    # Optimiseur simple\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.0008)\n",
        "\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    t = timer()\n",
        "    t.tic()\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.6,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    min_lr=1e-5\n",
        "    )\n",
        "    history = model.fit(\n",
        "        data.x_train, data.y_train,\n",
        "        validation_data=(data.x_test, data.y_test),\n",
        "        epochs=data.nb_epochs,\n",
        "        batch_size=data.batch_size,\n",
        "        shuffle=True,\n",
        "        verbose=2,\n",
        "        callbacks=[reduce_lr]\n",
        "    )\n",
        "    t.toc()\n",
        "    print(f\"✅ Entraînement terminé en {t.res():.1f} s\")\n",
        "    return model, history\n",
        "\n",
        "# Évaluation\n",
        "def test_model(data, model):\n",
        "    loss, acc = model.evaluate(data.x_test, data.y_test, verbose=2)\n",
        "    print(f\"Test loss: {loss:.4f}  Test accuracy: {acc:.4f}\")\n",
        "\n",
        "# (Facultatif) affichage des courbes\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['loss'], label='train loss'); plt.plot(history.history['val_loss'], label='val loss')\n",
        "    plt.legend(); plt.title('Loss')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['accuracy'], label='train acc'); plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "    plt.legend(); plt.title('Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "# MAIN\n",
        "if __name__ == '__main__':\n",
        "    # Hyperparamètres simples\n",
        "    NB_EPOCHS = 50\n",
        "    BATCH_SIZE = 64  # si VRAM limitée -> réduire à 32 ou 16\n",
        "\n",
        "    data = dataset(nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE)\n",
        "    model, history = train_model(data)\n",
        "    test_model(data, model)\n",
        "\n",
        "    # Sauvegarde\n",
        "    model.save(\"CIFAR10_VGG11_simple.h5\")\n",
        "    np.save(\"CIFAR10_xtest.npy\", data.x_test)\n",
        "    np.save(\"CIFAR10_ytest.npy\", data.y_test)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}